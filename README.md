Coursera Assignment: Getting and Cleaning Data Course Project
_____________________________________________________________
John A. Goodwin 
_____________________________________________________________
  The purpose of this project is to produce a tidy data set based on raw smartphone activity data. The raw data comes from the University of California, Irvine Center for Machine Learning and Intelligence Systems, available at <http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphone>. This project takes Activities of Daily Living data collected from the accelerometers from the Samsung Galaxy S smartphone and complies them into a tidy data set with only the mean and standard deveiation for each measurement recorded. 

    The raw data initially consisted of two randomly partitioned groups, the training data (70%) and test data (30%), listed in text files. Each group contained a subject identifier, activity label, vector of time/frequency variables, triaxial angular velocity data and triaxial acceleration data. For purposes of this assignment, analysis focuses on the X and Y files which include mean and standard deviation calculations for the inertial data. 
___________________________________________________________
The data set includes the following files

ReadMe.txt (this file)
CodeBook.txt: Defines labels used for data variables
run_analysis.R: Script used to process raw data into tidy data set
Tidy_Data.txt: Tidy data ready for analysis
___________________________________________________________
Method

Step 1. "Merge training and test data sets to create one data set"

   The run_analysis script first reads in the X and Y data using the read.table function. Each data file is named based on dimension (X and Y) and set (test and train). The script binds the test and train data for each variable using rbind() as each set has the same number of colums (X has 561, Y has 1) The total sets of X and Y data are then combined using the cbind() function as both have equal number of rows (102990). In so doing, the script satisfies one of the three components of tidy data: like variables in one table.
   
Step 2. "Appropriately labels the data set with descriptive variable names."

   The compiled data contains 562 columns, each a vector of variables for features of movement in the triaxial plane. The final column, 562, is the Y data which corresponds to activity (walking, etc) generating the measurements. However, each column header is a non-descriptive label (V1, V2,...V561, NA). The original data set includes a feature file with more descriptive labels for each feature of motion. The script imports this file, then converts its second column, the feature labels, to a vector. It appends to this vector a label for the final column, 'Activity Number' to replace the NA value carrried over from the Y data column header. It then renames the columns of the data set with these labels using colnames().

Step 3. "Extracts only the measurements on the mean and standard deviation for each measurements."

   The script extracts from the labeled column headers only the mean and standard deviation variables for each movement feature. It does this by using the grep() function to search for column headings that contain 'mean' or 'std', converting the results into a vector of numbers that correspond to the appropriate column heading. The script concocts the mean and std vectors into a single vector, sorts them using the sort() function. The final column name "Activity Number" does not meet the conditions and is thus not included in the vector. Because we want to include this data, the script appends the final column number '562' which corresponds to the activity data in the final column. The result is a vector of numbers for the columns corresponding to the mean and standard deviation measures for each activity plus the activity numbers. The script then subsets the total data set based on this vector, resulting in a data set that contains only the mean, SD and activity columns. 

   The resulting data set includes all measures with "mean" or "std" in the column heading, including those labeled "meanFreq". The rationale behind including these measures in the data set is to provide all measured which might be useful in further analysis. By including features such as "meanFreq", downstream users can decide for themselves whether the data is useful for their analysis or whether to exclude it. However, if in tidying the data we exclude these features, we deprive analysts their choice of analyzing this potentially useful information. Therefore, all features containing 'mean' are included, resulting in a dataframe with 10299 rows and 80 columns. 
   
Step 4. "Uses descriptive activity names to name the activities in the data set."

   All of the measurements in the current data set were generated by six different activities performed by test subjects. The numbers corresponding to those activities are contained in the final column of the 'extracted' data set. Labels for each activity are contained in a text file included with the original data, which the script imports using read.table(). It consists of two columns, numbers one to six in column one and descriptive labels like "walking" and "standing" in column two. The script lables the colums "Activity Number" and "Activity". This way the final column of the extracted data set and the first column of the activity label data set are labeled the same to enable the script to merge them. Before doing so, however, the script loads the 'plyr' and 'dplyr' packages which contain functions useful for data frame manipulation. One such function is the merge() function which takes as arguments both data sets and the "Activity Number" variable from each data set (with sort = FALSE), replacing the numbers in the final column with the name of the appropriate activity. The final column now contains the physical activities that correspond to each observation. 
   
Step 5. "From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject."

   The final step requires the inclusion of subject data, which the script imports from text files in both the train and test folders. Similar to the X and Y data, the script first binds the test and train subject data using rbind(), then appends the single column, 10299-row data frame to the main set using cbind(). As there is no additional information on the subjects include in the source data, their numerical identifiers 1-30 remain unchanged. The script loads the 'reshape2' library which allows for reshaping data frames. It identifies 'Subject' and 'Activity' as id variables and everything else as measurement variables using the melt() function. It then recasts the data into a new data frame using dcast() which has the Subjects listed in the first column, the activity they performed in the second column, and the mean for each of the measure variables in subsequent columns. The result is a data frame of 35 rows (five of the subjects performed two activities) and 81 columns, a 'wide' data set. The resultant data meets the tidy data components of each variable in its own column and each observation on a different row. 

________________________________________________________________________________
Works Referenced

Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013. 

https://thoughtfulbloke.wordpress.com/2015/09/09/getting-and-cleaning-the-assignment/
